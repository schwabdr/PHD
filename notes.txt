################## DETAILS #########################
When I move to new datasets - I'll need to 
1) train - train_standard, train_MI_estimator, train_MIAT_alpha
2) eval_baseline.py
3) eval_tests_01.py (change to each of the 4 models)
4) eval_tests_01_targeted.py (only choose one model if it makes sense)
5) eval_tests_02.py (based off of previous loss_study.py)

I should have taken better notes - 

I will assume at this point all 3 adv datasets are constructed from the resnet-new-100 model
"make_adv_examples.py" created all 3 datasets (and the .5 dataset which I'm not using so far)
nb_iters = 50 for all, eps_iter = .007
adv_test_images.npy (.03137 or 8/255)
adv_test_images.1.npy
adv_test_images.25.npy
(also adv_train for all datasets)

global_a, global_n - .03137 trained from datasets above
global_a.1, global_a.25 (same)

eval_baseline.py

################## SW Engineering ##################
name each model appropriately
use model_fns for list of models to pass between funcs

################## INFORMATION ##################
I see now that they define a special forward function for resnet_new.py
They can accept which layer's output they want to return ... and therefore they use this model
as the encoder. This will help me understand the paper a bit better now. The encoder is one of the outer layers
of the resnet model.

https://discuss.pytorch.org/t/how-can-you-train-your-model-on-large-batches-when-your-gpu-can-t-hold-more-than-a-few-samples/80581
https://discuss.pytorch.org/t/how-are-batches-split-across-multiple-gpus/91225

Tiny ImageNet
https://www.kaggle.com/datasets/akash2sharma/tiny-imagenet


These values were used for the adversarial dataset for initial MIAT training.
eps = 8/255.
eps_iter = .007
nb_iter = 40

explanation for "dim" parameter on Tensors
https://towardsdatascience.com/understanding-dimensions-in-pytorch-6edf9972d3be

When testing the loss - I have found that using the STD-ResNet leads to a much higher value for loss_mea_n vs loss_mea_a when attacking MIAT-ResNet


################## CURRENT WORK ##################
1) TRAIN RESNET18 FOR CIFAR 10 - NO AT - DONE
2) Make train_MI_estimator.py more efficient. - DONE
3) See Adversarial Training in "Adversarial Machine Learning at Scale" apply here

************ remove the eval step from the training of the MIAT - don't need it really unless I'm going to plot, and it will speed up training *************
************ optimize the PGD That is don't keep iterating if it's already fooling the target***************
Put a cap on iterations in my "eval_tests_01.py"

################## NORMALIZATION ##################
https://github.com/ernoult/scalingDTP/pull/36
And also see:
https://github.com/kuangliu/pytorch-cifar/issues/19
Standarization (this is what I really did)
https://machinelearningmastery.com/how-to-normalize-center-and-standardize-images-with-the-imagedatagenerator-in-keras/



################## CONDA ENVIRONMENT ##################
conda env phd04 - here's what I've done - pytorch 1.12 - I hope this keeps working.

conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch
conda install matplotlib
conda install -c conda-forge torchinfo






################## CODE SNIPPETS ##################
img, label = trainset.__getitem__(0)
    min = torch.min(img)
    max = torch.max(img)
    for i in range(trainset.__len__()):
        img, label = trainset.__getitem__(i)
        min_i = torch.min(img)
        max_i = torch.max(img)
        if min_i < min:
            min = min_i
        if max_i > max:
            max = max_i
    print(f"min: {torch.min(img)}")
    print(f"max: {torch.max(img)}")